<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <link rel="icon" type="image/svg+xml" sizes="any" href="/favicon.ico" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  
		<link href="/_app/immutable/assets/0.BL-tmMuE.css" rel="stylesheet">
		<link href="/_app/immutable/assets/3.IoD07seF.css" rel="stylesheet">
		<link rel="modulepreload" href="/_app/immutable/entry/start.Dr3mmzAa.js">
		<link rel="modulepreload" href="/_app/immutable/chunks/4oz8gmgq.js">
		<link rel="modulepreload" href="/_app/immutable/chunks/BBPmyNM4.js">
		<link rel="modulepreload" href="/_app/immutable/chunks/DwrScgbY.js">
		<link rel="modulepreload" href="/_app/immutable/entry/app.CL_y1PA5.js">
		<link rel="modulepreload" href="/_app/immutable/chunks/ClOl9dmH.js">
		<link rel="modulepreload" href="/_app/immutable/chunks/BZXONuDF.js">
		<link rel="modulepreload" href="/_app/immutable/nodes/0.BuVFTb2a.js">
		<link rel="modulepreload" href="/_app/immutable/chunks/CDJt_I-z.js">
		<link rel="modulepreload" href="/_app/immutable/chunks/VOoZFfsa.js">
		<link rel="modulepreload" href="/_app/immutable/chunks/BSWeh_4s.js">
		<link rel="modulepreload" href="/_app/immutable/chunks/CChnDLSk.js">
		<link rel="modulepreload" href="/_app/immutable/chunks/CWSYvbSR.js">
		<link rel="modulepreload" href="/_app/immutable/chunks/TSY2CcxY.js">
		<link rel="modulepreload" href="/_app/immutable/nodes/3.XKpBt9Ov.js">
		<link rel="modulepreload" href="/_app/immutable/chunks/BVP4zunF.js">
		<link rel="modulepreload" href="/_app/immutable/chunks/zfra-goi.js">
		<link rel="modulepreload" href="/_app/immutable/chunks/DnSXSBc1.js"><!--12qhfyh--><!--[--><script async src="https://www.googletagmanager.com/gtag/js?id=G-DTJQ3J1NVE"></script> <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() {
        dataLayer.push(arguments);
      }
      gtag("js", new Date());

      gtag("config", "G-DTJQ3J1NVE");
    </script><!--]--><!----><!--gsrl61--><meta name="description" content="RL for Consistency Models: Reward Guided Text-to-Image Generation with Fast Inference"/> <meta property="og:title" content="Owen Oertell – RLCM"/> <meta property="og:description" content="RL for Consistency Models: Reward Guided Text-to-Image Generation with Fast Inference"/> <meta property="og:image" content="https://www.owenoertell.com/assets/images/image_round_1.png"/> <meta name="twitter:card" content="summary_large_image"/><!----><title>Owen Oertell – RLCM</title>
</head>

<body>
  <div><!--[--><!--[--><!----><header class="layout-md flex justify-between items-start" data-sveltekit-noscroll="" data-sveltekit-preload-code="eager"><h1 class="font-bold text-black text-2xl mb-6"><a href="/">Owen Oertell</a> <!--[!--><!--]--></h1> <nav class="svelte-1elxaub"><!--[--><a href="/#publications" class="hover:text-black transition-colors svelte-1elxaub">publications</a><a href="/resume" class="hover:text-black transition-colors svelte-1elxaub">resume</a><a href="/#contact" class="hover:text-black transition-colors svelte-1elxaub">contact</a><!--]--></nav></header><!----> <!--[!--><!----><main><!--[--><!----><!----> <section class="layout-md"><a href="/#publications" class="text-neutral-500 hover:text-neutral-700 text-sm mb-4 inline-block">← back</a> <h1 class="text-2xl font-bold text-black dark:text-white mb-2">RL for Consistency Models: Reward Guided Text-to-Image Generation with Fast Inference</h1> <p class="text-neutral-600 dark:text-neutral-400 mb-4">Owen Oertell, Jonathan Daniel Chang, Yiyi Zhang, Kianté Brantley, and Wen Sun
</p> <div class="flex flex-wrap gap-3 items-center mb-8"><span class="venue-tag svelte-13q5ovy">RLC 2024</span> <!--[--><a href="https://arxiv.org/pdf/2404.03673" target="_blank" rel="noreferrer" class="action-btn svelte-13q5ovy">Paper <svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide-icon lucide lucide-arrow-up-right"><!--[--><!----><path d="M7 7h10v10"><!----></path><!----><!----><path d="M7 17 17 7"><!----></path><!----><!--]--><!--[--><!--[--><!--]--><!--]--></svg><!----></a><!--]--> <!--[--><button class="action-btn copy-btn svelte-13q5ovy"><span class="icon-wrapper svelte-13q5ovy"><!--[!--><span class="icon svelte-13q5ovy"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide-icon lucide lucide-copy"><!--[--><!----><rect width="14" height="14" x="8" y="8" rx="2" ry="2"><!----></rect><!----><!----><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"><!----></path><!----><!--]--><!--[--><!--[--><!--]--><!--]--></svg><!----></span><!--]--></span> <span>Copy BibTeX</span></button><!--]--></div> <!--[--><div class="mb-8"><h2 class="text-sm uppercase text-neutral-500 mb-2">Abstract</h2> <div class="abstract-content text-neutral-700 dark:text-neutral-300 leading-relaxed svelte-13q5ovy"><!----><p>Reinforcement learning (RL) has improved guided image generation with diffusion models by directly optimizing rewards that capture image quality, aesthetics, and instruction following capabilities. However, the resulting generative policies inherit the same iterative sampling process of diffusion models that causes slow generation. To overcome this limitation, consistency models proposed learning a new class of generative models that directly map noise to data, resulting in a model that can generate an image in as few as one sampling iteration. In this work, to optimize text-to-image generative models for task specific rewards and enable fast training and inference, we propose a framework for fine-tuning consistency models via RL. Our framework, called Reinforcement Learning for Consistency Model (RLCM), frames the iterative inference process of a consistency model as an RL procedure. Comparing to RL finetuned diffusion models, RLCM trains significantly faster, improves the quality of the generation measured under the reward objectives, and speeds up the inference procedure by generating high quality images with as few as two inference steps. Experimentally, we show that RLCM can adapt text-to-image consistency models to objectives that are challenging to express with prompting, such as image compressibility, and those derived from human feedback, such as aesthetic quality. Our code is available <a href="https://rlcm.owenoertell.com">here</a>.</p>
<!----></div></div><!--]--></section><!----><!--]--></main><!----><!--]--><!----><!--]--> <!--[!--><!--]--><!--]-->
			
			<script>
				{
					__sveltekit_oh8fdc = {
						base: ""
					};

					const element = document.currentScript.parentElement;

					Promise.all([
						import("/_app/immutable/entry/start.Dr3mmzAa.js"),
						import("/_app/immutable/entry/app.CL_y1PA5.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 3],
							data: [null,{type:"data",data:null,uses:{}}],
							form: null,
							error: null
						});
					});
				}
			</script>
		</div>
</body>

</html>